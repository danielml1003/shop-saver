component (Python) downloads and processes raw price lists from retailer data feeds, while the **frontend** (TypeScript/React) provides an interactive web interface for searching items, browsing stores and performing basket‑price comparisons.

The project is organised into two top‑level directories:

| Directory       | Description |
|-----------------|-------------|
| `service/`      | Python scripts and classes for downloading and extracting price data from various retailer websites.  It contains an abstract base class and concrete downloaders for different store types, along with helper scripts. |
| `frontend/`     | A React application written in TypeScript using Material‑UI.  It provides pages for item search, store listing and price comparison.  It also defines API service calls and shared type definitions. |

## Service (Python)

### Purpose

The service pulls pricing information published by Israeli supermarket chains.  Retailers publish daily price lists as compressed XML files.  Shop‑Saver downloads these files, decompresses them and, in a future version, will load them into a database for use by the frontend.  
Currently, the scripts print or save the extracted XML files, but they demonstrate how to fetch and process the data.

### Base class and utilities

The base downloader, defined in `service/downloaders/base.py`, encapsulates the common logic for all downloaders:

- Manage a **download directory**, creating it if necessary.  
- **Generate download URLs** by combining a base URL, chain ID, store ID and timestamp.  Subclasses override the `_generate_urls` method to produce the appropriate URL pattern for each retailer.
- **Download files** using `requests` with error handling and timeouts.  Files are saved with a `.gz` extension by default and are removed if a download fails.
- **Extract compressed files**.  The base class examines the magic number to determine whether a file is a `.gz` or a `.zip` archive and extracts the inner XML accordingly.  It removes the compressed file after extraction and returns the path to the extracted XML.  
- **Process multiple downloads**.  The `process_store` method iterates over all generated URLs, downloads and extracts each file, and counts successes and failures.

### Store‑specific downloaders

Concrete subclasses in `service/downloaders/` handle differences in URL patterns and file extensions:

- **`OriginalStoreDownloader`** constructs URLs ending with `.gz` and expects hourly timestamps.  It is used by chains such as King, Maayan and GoodPharm.  
- **`OneStoreDownloader`** constructs URLs ending with `.zip` for chains that publish their data in ZIP format but are otherwise similar to the original type.  
- Additional subclasses (e.g., for “mega” or “cerberus” site types) can be added to support other publishing formats.

The `service/storesJsonUrl.py` module defines configuration dictionaries for each retailer.  Each entry provides the download base URL (`Url`), file types (`WFileType`), chain ID and store IDs, along with a timestamp generator.  The downloaders import these configurations and pass them to the base class.

### Scripts

- **`service/main.py`** instantiates the King downloader and calls its `download()` method.  It demonstrates how to run a specific store downloader.  You can modify it to instantiate other downloaders or to schedule downloads.
- **`service/requestZip.py`** shows a standalone approach for retrieving price lists when the retailer provides a JSON endpoint.  It fetches a JSON descriptor containing a file URL, downloads the compressed file, extracts it and prints the XML content.  This script also includes helper functions to clean existing files, manage the download directory and pretty‑print the XML.

### Running the service

1. Ensure Python 3.9+ is installed.  
2. Install dependencies (currently only `requests`):
   ```bash
   pip install requests
   ```
3. Navigate to the `service/` directory.  
4. To download price lists for King stores, run:
   ```bash
   python main.py
   ```
   The script will generate URLs for each store and time slot, download each `.gz` file, extract the XML and save it under `service/downloads/`.  

> **Note:** The current service prints and stores the raw XML.  Future enhancements could parse this XML into a structured database (e.g., PostgreSQL) and expose a REST API for the frontend.

## Frontend (React + TypeScript)

### Purpose

The web interface allows users to browse available stores, search for items and compare the price of a shopping basket across nearby stores.  It uses Material‑UI for layout and styling, supports right‑to‑left (RTL) languages and is localised with Hebrew labels.

### Structure

The React app is located in `frontend/src/` and is organised by pages, components, services and type definitions:

- **Pages (`src/pages/`)** – define high‑level views.  
  - **ItemsPage**: displays a filterable and paginated list of products.  It fetches items from the API service, applies search filters (name, price range, manufacturer, city) and shows results in a responsive grid.  
  - **StoresPage**: lists stores with details such as chain ID, address and last update.  Each store is displayed in a card with icons for location and update time.  
  - **ComparePage**: lets users enter a list of items and their location (latitude/longitude).  It calls a price comparison endpoint, then shows the total price and item availability for each nearby store.

- **Components (`src/components/`)** – reusable UI pieces.  Examples include `Header` (navigation bar), `ItemCard` (displays product information), and `SearchFilters` (form controls for filtering items).  These components utilise Material‑UI components like `Card`, `Typography`, `TextField` and `Pagination`.

- **Services (`src/services/api.ts`)** – defines the API service used throughout the frontend.  It wraps Axios requests to backend endpoints and currently returns mock data for stores and items.  Functions include:
  - `getStores()`: returns a list of stores.  
  - `getItems()`: returns paginated items filtered by name, price or manufacturer.  
  - `comparePrices()`: posts a basket and location to the `/api/compare-prices` endpoint and returns price comparison results.  
  - `getNearbyStores()` and other helpers for future backend integration.

- **Types (`src/types/index.ts`)** – centralises TypeScript interfaces for stores, items, API responses and price‑comparison payloads.

### Running the frontend

1. Ensure Node.js (≥ 16) and npm or Yarn are installed.  
2. Navigate to the `frontend/` directory.  
3. Install dependencies:
   ```bash
   npm install
   ```
4. Start the development server:
   ```bash
   npm start
   ```
   The app will run at `http://localhost:3000` by default.  The environment variable `REACT_APP_API_URL` can point to your backend when available; otherwise the mock API is used.

### Future work

- **Backend API integration** – implement a REST API (e.g., using FastAPI or Express) that reads the processed XML files, stores them in a database and exposes endpoints for `getStores`, `getItems`, `getNearbyStores` and `comparePrices`.  Update `src/services/api.ts` to call these endpoints instead of returning mock data.
- **Data persistence** – parse XML price lists into relational tables.  Use indexes on item codes, store IDs and timestamps to support efficient queries.
- **Scheduling and automation** – add a scheduler (cron or Celery) to run the downloaders regularly and update the database.
- **Additional retailers** – extend the downloader subclasses to support `mega`, `cerberus` and other site types defined in `storesJsonUrl.py`.
- **Internationalisation (i18n)** – though the current UI is Hebrew‑centric, adding language files would make the app multilingual.

## Conclusion

Shop‑Saver demonstrates the end‑to‑end flow of fetching price data from retailers and presenting it to users in an accessible web interface.  The Python service handles the complexities of downloading and extracting data from different retailer platforms, while the React frontend focuses on user experience and client‑side filtering.  With further development—such as a proper backend API, database integration and more retailer support—Shop‑Saver can become a powerful tool for consumers seeking the best prices.

